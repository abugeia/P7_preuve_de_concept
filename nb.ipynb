{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "learnopencv\n",
    "pyimagesearch\n",
    "\n",
    "https://github.com/ultralytics/yolov5/issues/36\n",
    "mAP \n",
    "https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2\n",
    "https://blog.paperspace.com/mean-average-precision/\n",
    "\n",
    "# P7 Object Detection with YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_folder = 'https://github.com/ultralytics/yolov5/releases/download/v1.0/'\n",
    "val_file = 'coco2017val.zip'\n",
    "# tmp_name = 'tmp.zip'\n",
    "extract_path = '../datasets'\n",
    "\n",
    "# Download COCO val2017\n",
    "torch.hub.download_url_to_file(url_folder + val_file, 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ./datasets && rm tmp.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v3 & v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and test the model with eval file\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "!pip install -qr yolov5/requirements.txt\n",
    "\n",
    "# test on sample\n",
    "!python yolov5/detect.py --weights yolov5/yolov5s.pt --img 640 --conf 0.25 --source yolov5/data/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov3'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['yolov3/yolov3.pt'], source='yolov3/data/images/', img_size=640, conf_thres=0.25, iou_thres=0.45, max_det=1000, device='', view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False)\n",
      "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3.pt to yolov3\\yolov3.pt...\n",
      "\n",
      "image 1/2 c:\\Users\\Admin\\Documents\\Formation_ML\\7_preuve_de_concept\\yolov3\\data\\images\\bus.jpg: 640x480 4 persons, 1 bus, Done. (1.191s)\n",
      "image 2/2 c:\\Users\\Admin\\Documents\\Formation_ML\\7_preuve_de_concept\\yolov3\\data\\images\\zidane.jpg: 384x640 2 persons, 3 ties, Done. (0.868s)\n",
      "Results saved to runs\\detect\\exp2\n",
      "Done. (2.201s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv3  v9.5.0-13-g1be3170 torch 1.9.1+cpu CPU\n",
      "\n",
      "\n",
      "  0%|          | 0.00/118M [00:00<?, ?B/s]\n",
      "  0%|          | 48.0k/118M [00:00<06:55, 299kB/s]\n",
      "  0%|          | 128k/118M [00:00<05:10, 399kB/s] \n",
      "  0%|          | 240k/118M [00:00<03:49, 541kB/s]\n",
      "  0%|          | 376k/118M [00:00<03:14, 637kB/s]\n",
      "  1%|          | 624k/118M [00:00<02:15, 911kB/s]\n",
      "  1%|          | 944k/118M [00:00<01:25, 1.43MB/s]\n",
      "  1%|          | 1.20M/118M [00:01<01:08, 1.79MB/s]\n",
      "  1%|▏         | 1.64M/118M [00:01<00:49, 2.46MB/s]\n",
      "  2%|▏         | 2.25M/118M [00:01<00:35, 3.47MB/s]\n",
      "  2%|▏         | 2.72M/118M [00:01<00:31, 3.87MB/s]\n",
      "  3%|▎         | 3.33M/118M [00:01<00:26, 4.55MB/s]\n",
      "  3%|▎         | 3.86M/118M [00:01<00:24, 4.82MB/s]\n",
      "  4%|▍         | 4.49M/118M [00:01<00:22, 5.34MB/s]\n",
      "  4%|▍         | 5.08M/118M [00:01<00:21, 5.47MB/s]\n",
      "  5%|▍         | 5.77M/118M [00:01<00:19, 5.98MB/s]\n",
      "  5%|▌         | 6.41M/118M [00:01<00:19, 6.17MB/s]\n",
      "  6%|▌         | 7.02M/118M [00:02<00:18, 6.21MB/s]\n",
      "  7%|▋         | 7.70M/118M [00:02<00:17, 6.47MB/s]\n",
      "  7%|▋         | 8.41M/118M [00:02<00:17, 6.70MB/s]\n",
      "  8%|▊         | 9.16M/118M [00:02<00:16, 6.95MB/s]\n",
      "  8%|▊         | 9.89M/118M [00:02<00:15, 7.13MB/s]\n",
      "  9%|▉         | 10.7M/118M [00:02<00:15, 7.38MB/s]\n",
      " 10%|▉         | 11.4M/118M [00:02<00:19, 5.80MB/s]\n",
      " 11%|█         | 12.5M/118M [00:02<00:14, 7.42MB/s]\n",
      " 11%|█         | 13.3M/118M [00:03<00:15, 7.30MB/s]\n",
      " 12%|█▏        | 14.1M/118M [00:03<00:15, 6.92MB/s]\n",
      " 12%|█▏        | 14.8M/118M [00:03<00:22, 4.93MB/s]\n",
      " 13%|█▎        | 16.0M/118M [00:03<00:16, 6.49MB/s]\n",
      " 14%|█▍        | 16.7M/118M [00:03<00:18, 5.73MB/s]\n",
      " 15%|█▍        | 17.4M/118M [00:03<00:20, 5.25MB/s]\n",
      " 15%|█▌        | 18.0M/118M [00:04<00:28, 3.65MB/s]\n",
      " 16%|█▌        | 18.9M/118M [00:04<00:22, 4.69MB/s]\n",
      " 16%|█▋        | 19.5M/118M [00:04<00:25, 4.11MB/s]\n",
      " 17%|█▋        | 20.0M/118M [00:04<00:26, 3.88MB/s]\n",
      " 17%|█▋        | 20.5M/118M [00:04<00:27, 3.78MB/s]\n",
      " 18%|█▊        | 20.9M/118M [00:04<00:28, 3.64MB/s]\n",
      " 18%|█▊        | 21.3M/118M [00:05<00:30, 3.33MB/s]\n",
      " 18%|█▊        | 21.6M/118M [00:05<00:32, 3.17MB/s]\n",
      " 19%|█▊        | 22.0M/118M [00:05<00:30, 3.29MB/s]\n",
      " 19%|█▉        | 22.3M/118M [00:05<00:30, 3.27MB/s]\n",
      " 19%|█▉        | 22.6M/118M [00:05<00:33, 2.98MB/s]\n",
      " 19%|█▉        | 23.1M/118M [00:05<00:29, 3.42MB/s]\n",
      " 20%|█▉        | 23.4M/118M [00:05<00:29, 3.43MB/s]\n",
      " 20%|██        | 23.8M/118M [00:05<00:28, 3.47MB/s]\n",
      " 20%|██        | 24.1M/118M [00:05<00:28, 3.46MB/s]\n",
      " 21%|██        | 24.5M/118M [00:06<00:28, 3.47MB/s]\n",
      " 21%|██        | 24.9M/118M [00:06<00:27, 3.57MB/s]\n",
      " 21%|██▏       | 25.2M/118M [00:06<00:27, 3.56MB/s]\n",
      " 22%|██▏       | 25.6M/118M [00:06<00:27, 3.58MB/s]\n",
      " 22%|██▏       | 25.9M/118M [00:06<00:26, 3.63MB/s]\n",
      " 22%|██▏       | 26.3M/118M [00:06<00:26, 3.58MB/s]\n",
      " 22%|██▏       | 26.7M/118M [00:06<00:26, 3.66MB/s]\n",
      " 23%|██▎       | 27.0M/118M [00:06<00:26, 3.65MB/s]\n",
      " 23%|██▎       | 27.4M/118M [00:06<00:25, 3.74MB/s]\n",
      " 23%|██▎       | 27.8M/118M [00:07<00:25, 3.66MB/s]\n",
      " 24%|██▎       | 28.1M/118M [00:07<00:26, 3.60MB/s]\n",
      " 24%|██▍       | 28.5M/118M [00:07<00:25, 3.75MB/s]\n",
      " 24%|██▍       | 28.9M/118M [00:07<00:26, 3.61MB/s]\n",
      " 25%|██▍       | 29.2M/118M [00:07<00:25, 3.61MB/s]\n",
      " 25%|██▍       | 29.6M/118M [00:07<00:24, 3.76MB/s]\n",
      " 25%|██▌       | 30.0M/118M [00:07<00:25, 3.68MB/s]\n",
      " 26%|██▌       | 30.4M/118M [00:07<00:23, 3.88MB/s]\n",
      " 26%|██▌       | 30.8M/118M [00:07<00:24, 3.75MB/s]\n",
      " 26%|██▋       | 31.1M/118M [00:07<00:25, 3.63MB/s]\n",
      " 27%|██▋       | 31.6M/118M [00:08<00:23, 3.88MB/s]\n",
      " 27%|██▋       | 32.0M/118M [00:08<00:24, 3.71MB/s]\n",
      " 27%|██▋       | 32.3M/118M [00:08<00:24, 3.66MB/s]\n",
      " 28%|██▊       | 32.7M/118M [00:08<00:24, 3.68MB/s]\n",
      " 28%|██▊       | 33.1M/118M [00:08<00:23, 3.80MB/s]\n",
      " 28%|██▊       | 33.4M/118M [00:08<00:23, 3.79MB/s]\n",
      " 29%|██▊       | 33.8M/118M [00:08<00:33, 2.63MB/s]\n",
      " 29%|██▉       | 34.6M/118M [00:08<00:22, 3.93MB/s]\n",
      " 30%|██▉       | 35.1M/118M [00:09<00:26, 3.35MB/s]\n",
      " 30%|██▉       | 35.5M/118M [00:09<00:27, 3.14MB/s]\n",
      " 30%|███       | 35.8M/118M [00:09<00:28, 3.03MB/s]\n",
      " 31%|███       | 36.1M/118M [00:09<00:27, 3.11MB/s]\n",
      " 31%|███       | 36.5M/118M [00:09<00:28, 3.02MB/s]\n",
      " 31%|███       | 36.8M/118M [00:09<00:29, 2.88MB/s]\n",
      " 31%|███▏      | 37.1M/118M [00:09<00:27, 3.11MB/s]\n",
      " 32%|███▏      | 37.5M/118M [00:10<00:29, 2.90MB/s]\n",
      " 32%|███▏      | 37.7M/118M [00:10<00:29, 2.87MB/s]\n",
      " 32%|███▏      | 38.1M/118M [00:10<00:28, 3.00MB/s]\n",
      " 32%|███▏      | 38.4M/118M [00:10<00:28, 2.98MB/s]\n",
      " 33%|███▎      | 38.7M/118M [00:10<00:38, 2.17MB/s]\n",
      " 33%|███▎      | 39.4M/118M [00:10<00:25, 3.24MB/s]\n",
      " 34%|███▎      | 39.7M/118M [00:10<00:27, 2.97MB/s]\n",
      " 34%|███▍      | 40.1M/118M [00:11<00:39, 2.08MB/s]\n",
      " 34%|███▍      | 40.6M/118M [00:11<00:30, 2.67MB/s]\n",
      " 35%|███▍      | 40.9M/118M [00:11<00:34, 2.34MB/s]\n",
      " 35%|███▍      | 41.2M/118M [00:11<00:37, 2.17MB/s]\n",
      " 35%|███▍      | 41.5M/118M [00:11<00:39, 2.06MB/s]\n",
      " 35%|███▌      | 41.7M/118M [00:11<00:40, 2.01MB/s]\n",
      " 35%|███▌      | 41.9M/118M [00:12<00:42, 1.91MB/s]\n",
      " 36%|███▌      | 42.1M/118M [00:12<00:41, 1.94MB/s]\n",
      " 36%|███▌      | 42.3M/118M [00:12<00:42, 1.89MB/s]\n",
      " 36%|███▌      | 42.5M/118M [00:12<00:41, 1.91MB/s]\n",
      " 36%|███▌      | 42.7M/118M [00:12<00:42, 1.89MB/s]\n",
      " 36%|███▌      | 42.9M/118M [00:12<01:01, 1.30MB/s]\n",
      " 37%|███▋      | 43.3M/118M [00:12<00:40, 1.96MB/s]\n",
      " 37%|███▋      | 43.5M/118M [00:13<00:44, 1.76MB/s]\n",
      " 37%|███▋      | 43.7M/118M [00:13<00:47, 1.66MB/s]\n",
      " 37%|███▋      | 43.9M/118M [00:13<00:49, 1.57MB/s]\n",
      " 37%|███▋      | 44.1M/118M [00:13<00:50, 1.54MB/s]\n",
      " 37%|███▋      | 44.3M/118M [00:13<00:50, 1.55MB/s]\n",
      " 37%|███▋      | 44.4M/118M [00:13<00:51, 1.51MB/s]\n",
      " 38%|███▊      | 44.6M/118M [00:13<00:51, 1.51MB/s]\n",
      " 38%|███▊      | 44.7M/118M [00:13<00:51, 1.49MB/s]\n",
      " 38%|███▊      | 44.9M/118M [00:14<00:51, 1.50MB/s]\n",
      " 38%|███▊      | 45.0M/118M [00:14<00:51, 1.48MB/s]\n",
      " 38%|███▊      | 45.2M/118M [00:14<00:52, 1.47MB/s]\n",
      " 38%|███▊      | 45.3M/118M [00:14<00:50, 1.52MB/s]\n",
      " 38%|███▊      | 45.5M/118M [00:14<00:50, 1.52MB/s]\n",
      " 39%|███▊      | 45.7M/118M [00:14<00:49, 1.55MB/s]\n",
      " 39%|███▊      | 45.8M/118M [00:14<00:49, 1.55MB/s]\n",
      " 39%|███▉      | 46.0M/118M [00:14<00:49, 1.54MB/s]\n",
      " 39%|███▉      | 46.1M/118M [00:14<00:49, 1.55MB/s]\n",
      " 39%|███▉      | 46.3M/118M [00:15<00:48, 1.56MB/s]\n",
      " 39%|███▉      | 46.5M/118M [00:15<00:47, 1.58MB/s]\n",
      " 39%|███▉      | 46.6M/118M [00:15<00:47, 1.59MB/s]\n",
      " 39%|███▉      | 46.8M/118M [00:15<00:47, 1.58MB/s]\n",
      " 40%|███▉      | 46.9M/118M [00:15<00:47, 1.59MB/s]\n",
      " 40%|███▉      | 47.1M/118M [00:15<00:46, 1.61MB/s]\n",
      " 40%|███▉      | 47.3M/118M [00:15<00:47, 1.58MB/s]\n",
      " 40%|████      | 47.4M/118M [00:15<00:46, 1.61MB/s]\n",
      " 40%|████      | 47.6M/118M [00:15<00:46, 1.61MB/s]\n",
      " 40%|████      | 47.8M/118M [00:15<00:45, 1.62MB/s]\n",
      " 40%|████      | 47.9M/118M [00:16<00:45, 1.62MB/s]\n",
      " 41%|████      | 48.1M/118M [00:16<00:46, 1.60MB/s]\n",
      " 41%|████      | 48.2M/118M [00:16<00:44, 1.65MB/s]\n",
      " 41%|████      | 48.4M/118M [00:16<00:44, 1.65MB/s]\n",
      " 41%|████      | 48.6M/118M [00:16<00:45, 1.62MB/s]\n",
      " 41%|████      | 48.7M/118M [00:16<00:45, 1.61MB/s]\n",
      " 41%|████▏     | 48.9M/118M [00:16<00:45, 1.60MB/s]\n",
      " 41%|████▏     | 49.0M/118M [00:16<00:44, 1.65MB/s]\n",
      " 42%|████▏     | 49.2M/118M [00:16<00:44, 1.65MB/s]\n",
      " 42%|████▏     | 49.4M/118M [00:17<00:44, 1.62MB/s]\n",
      " 42%|████▏     | 49.5M/118M [00:17<00:44, 1.61MB/s]\n",
      " 42%|████▏     | 49.7M/118M [00:17<00:45, 1.60MB/s]\n",
      " 42%|████▏     | 49.8M/118M [00:17<00:45, 1.58MB/s]\n",
      " 42%|████▏     | 50.0M/118M [00:17<00:46, 1.55MB/s]\n",
      " 42%|████▏     | 50.2M/118M [00:17<00:43, 1.65MB/s]\n",
      " 43%|████▎     | 50.4M/118M [00:17<00:42, 1.67MB/s]\n",
      " 43%|████▎     | 50.5M/118M [00:17<00:43, 1.65MB/s]\n",
      " 43%|████▎     | 50.7M/118M [00:17<00:42, 1.66MB/s]\n",
      " 43%|████▎     | 50.9M/118M [00:17<00:43, 1.65MB/s]\n",
      " 43%|████▎     | 51.0M/118M [00:18<00:44, 1.60MB/s]\n",
      " 43%|████▎     | 51.2M/118M [00:18<00:43, 1.64MB/s]\n",
      " 43%|████▎     | 51.4M/118M [00:18<00:42, 1.64MB/s]\n",
      " 43%|████▎     | 51.5M/118M [00:18<00:42, 1.64MB/s]\n",
      " 44%|████▎     | 51.7M/118M [00:18<00:42, 1.65MB/s]\n",
      " 44%|████▍     | 51.8M/118M [00:18<00:43, 1.61MB/s]\n",
      " 44%|████▍     | 52.0M/118M [00:18<00:42, 1.65MB/s]\n",
      " 44%|████▍     | 52.2M/118M [00:18<00:42, 1.62MB/s]\n",
      " 44%|████▍     | 52.3M/118M [00:18<00:42, 1.63MB/s]\n",
      " 44%|████▍     | 52.5M/118M [00:19<00:42, 1.63MB/s]\n",
      " 44%|████▍     | 52.7M/118M [00:19<00:42, 1.61MB/s]\n",
      " 45%|████▍     | 52.9M/118M [00:19<00:40, 1.69MB/s]\n",
      " 45%|████▍     | 53.0M/118M [00:19<00:42, 1.63MB/s]\n",
      " 45%|████▍     | 53.2M/118M [00:19<00:42, 1.62MB/s]\n",
      " 45%|████▌     | 53.3M/118M [00:19<00:40, 1.67MB/s]\n",
      " 45%|████▌     | 53.5M/118M [00:19<00:41, 1.64MB/s]\n",
      " 45%|████▌     | 53.7M/118M [00:19<00:40, 1.69MB/s]\n",
      " 45%|████▌     | 53.9M/118M [00:19<00:40, 1.67MB/s]\n",
      " 46%|████▌     | 54.0M/118M [00:19<00:41, 1.63MB/s]\n",
      " 46%|████▌     | 54.2M/118M [00:20<00:39, 1.70MB/s]\n",
      " 46%|████▌     | 54.4M/118M [00:20<00:40, 1.67MB/s]\n",
      " 46%|████▌     | 54.5M/118M [00:20<00:39, 1.69MB/s]\n",
      " 46%|████▌     | 54.7M/118M [00:20<00:39, 1.70MB/s]\n",
      " 46%|████▋     | 54.9M/118M [00:20<00:39, 1.69MB/s]\n",
      " 46%|████▋     | 55.0M/118M [00:20<00:38, 1.71MB/s]\n",
      " 47%|████▋     | 55.2M/118M [00:20<00:38, 1.71MB/s]\n",
      " 47%|████▋     | 55.4M/118M [00:20<00:37, 1.76MB/s]\n",
      " 47%|████▋     | 55.6M/118M [00:20<00:38, 1.72MB/s]\n",
      " 47%|████▋     | 55.8M/118M [00:21<00:37, 1.76MB/s]\n",
      " 47%|████▋     | 56.0M/118M [00:21<00:36, 1.80MB/s]\n",
      " 47%|████▋     | 56.1M/118M [00:21<00:37, 1.76MB/s]\n",
      " 48%|████▊     | 56.3M/118M [00:21<00:35, 1.82MB/s]\n",
      " 48%|████▊     | 56.5M/118M [00:21<00:35, 1.82MB/s]\n",
      " 48%|████▊     | 56.7M/118M [00:21<00:35, 1.84MB/s]\n",
      " 48%|████▊     | 56.9M/118M [00:21<00:34, 1.86MB/s]\n",
      " 48%|████▊     | 57.1M/118M [00:21<00:34, 1.85MB/s]\n",
      " 48%|████▊     | 57.3M/118M [00:21<00:33, 1.91MB/s]\n",
      " 48%|████▊     | 57.5M/118M [00:21<00:33, 1.88MB/s]\n",
      " 49%|████▊     | 57.7M/118M [00:22<00:32, 1.93MB/s]\n",
      " 49%|████▉     | 57.9M/118M [00:22<00:32, 1.98MB/s]\n",
      " 49%|████▉     | 58.1M/118M [00:22<00:31, 1.99MB/s]\n",
      " 49%|████▉     | 58.2M/118M [00:22<00:31, 1.99MB/s]\n",
      " 49%|████▉     | 58.5M/118M [00:22<00:31, 2.02MB/s]\n",
      " 50%|████▉     | 58.7M/118M [00:22<00:30, 2.05MB/s]\n",
      " 50%|████▉     | 58.9M/118M [00:22<00:30, 2.06MB/s]\n",
      " 50%|████▉     | 59.1M/118M [00:22<00:29, 2.12MB/s]\n",
      " 50%|█████     | 59.3M/118M [00:22<00:29, 2.13MB/s]\n",
      " 50%|█████     | 59.5M/118M [00:23<00:28, 2.17MB/s]\n",
      " 50%|█████     | 59.8M/118M [00:23<00:27, 2.22MB/s]\n",
      " 51%|█████     | 60.0M/118M [00:23<00:27, 2.21MB/s]\n",
      " 51%|█████     | 60.2M/118M [00:23<00:27, 2.26MB/s]\n",
      " 51%|█████     | 60.4M/118M [00:23<00:26, 2.30MB/s]\n",
      " 51%|█████     | 60.7M/118M [00:23<00:25, 2.33MB/s]\n",
      " 51%|█████▏    | 60.9M/118M [00:23<00:25, 2.38MB/s]\n",
      " 52%|█████▏    | 61.2M/118M [00:23<00:25, 2.34MB/s]\n",
      " 52%|█████▏    | 61.4M/118M [00:23<00:24, 2.49MB/s]\n",
      " 52%|█████▏    | 61.7M/118M [00:23<00:23, 2.49MB/s]\n",
      " 52%|█████▏    | 61.9M/118M [00:24<00:23, 2.52MB/s]\n",
      " 52%|█████▏    | 62.2M/118M [00:24<00:22, 2.60MB/s]\n",
      " 53%|█████▎    | 62.5M/118M [00:24<00:22, 2.56MB/s]\n",
      " 53%|█████▎    | 62.8M/118M [00:24<00:21, 2.74MB/s]\n",
      " 53%|█████▎    | 63.0M/118M [00:24<00:21, 2.68MB/s]\n",
      " 53%|█████▎    | 63.3M/118M [00:24<00:20, 2.79MB/s]\n",
      " 54%|█████▎    | 63.6M/118M [00:24<00:20, 2.82MB/s]\n",
      " 54%|█████▍    | 63.9M/118M [00:24<00:19, 2.86MB/s]\n",
      " 54%|█████▍    | 64.2M/118M [00:24<00:19, 2.98MB/s]\n",
      " 54%|█████▍    | 64.5M/118M [00:24<00:18, 2.98MB/s]\n",
      " 55%|█████▍    | 64.8M/118M [00:25<00:18, 3.04MB/s]\n",
      " 55%|█████▍    | 65.1M/118M [00:25<00:18, 3.07MB/s]\n",
      " 55%|█████▌    | 65.5M/118M [00:25<00:17, 3.16MB/s]\n",
      " 56%|█████▌    | 65.8M/118M [00:25<00:16, 3.25MB/s]\n",
      " 56%|█████▌    | 66.1M/118M [00:25<00:16, 3.32MB/s]\n",
      " 56%|█████▌    | 66.5M/118M [00:25<00:16, 3.40MB/s]\n",
      " 56%|█████▋    | 66.8M/118M [00:25<00:16, 3.38MB/s]\n",
      " 57%|█████▋    | 67.2M/118M [00:25<00:15, 3.56MB/s]\n",
      " 57%|█████▋    | 67.6M/118M [00:25<00:15, 3.55MB/s]\n",
      " 57%|█████▋    | 67.9M/118M [00:26<00:14, 3.62MB/s]\n",
      " 58%|█████▊    | 68.3M/118M [00:26<00:14, 3.74MB/s]\n",
      " 58%|█████▊    | 68.7M/118M [00:26<00:13, 3.78MB/s]\n",
      " 58%|█████▊    | 69.1M/118M [00:26<00:13, 3.94MB/s]\n",
      " 59%|█████▊    | 69.5M/118M [00:26<00:13, 3.94MB/s]\n",
      " 59%|█████▉    | 70.0M/118M [00:26<00:12, 4.06MB/s]\n",
      " 59%|█████▉    | 70.3M/118M [00:26<00:17, 2.92MB/s]\n",
      " 60%|██████    | 71.2M/118M [00:26<00:11, 4.36MB/s]\n",
      " 61%|██████    | 71.7M/118M [00:27<00:12, 3.95MB/s]\n",
      " 61%|██████    | 72.1M/118M [00:27<00:13, 3.73MB/s]\n",
      " 61%|██████    | 72.5M/118M [00:27<00:13, 3.55MB/s]\n",
      " 62%|██████▏   | 72.9M/118M [00:27<00:13, 3.50MB/s]\n",
      " 62%|██████▏   | 73.3M/118M [00:27<00:22, 2.06MB/s]\n",
      " 62%|██████▏   | 73.7M/118M [00:27<00:22, 2.13MB/s]\n",
      " 62%|██████▏   | 74.0M/118M [00:28<00:20, 2.29MB/s]\n",
      " 63%|██████▎   | 74.2M/118M [00:28<00:25, 1.82MB/s]\n",
      " 63%|██████▎   | 74.6M/118M [00:28<00:24, 1.89MB/s]\n",
      " 63%|██████▎   | 74.9M/118M [00:28<00:21, 2.10MB/s]\n",
      " 63%|██████▎   | 75.1M/118M [00:28<00:21, 2.14MB/s]\n",
      " 64%|██████▎   | 75.4M/118M [00:28<00:19, 2.35MB/s]\n",
      " 64%|██████▍   | 75.7M/118M [00:28<00:19, 2.34MB/s]\n",
      " 64%|██████▍   | 75.9M/118M [00:29<00:26, 1.69MB/s]\n",
      " 65%|██████▍   | 76.5M/118M [00:29<00:16, 2.65MB/s]\n",
      " 65%|██████▍   | 76.9M/118M [00:29<00:18, 2.40MB/s]\n",
      " 65%|██████▌   | 77.1M/118M [00:29<00:19, 2.24MB/s]\n",
      " 65%|██████▌   | 77.4M/118M [00:29<00:20, 2.15MB/s]\n",
      " 66%|██████▌   | 77.6M/118M [00:29<00:20, 2.09MB/s]\n",
      " 66%|██████▌   | 77.8M/118M [00:30<00:27, 1.55MB/s]\n",
      " 66%|██████▌   | 78.3M/118M [00:30<00:19, 2.11MB/s]\n",
      " 66%|██████▋   | 78.5M/118M [00:30<00:22, 1.89MB/s]\n",
      " 66%|██████▋   | 78.8M/118M [00:30<00:23, 1.76MB/s]\n",
      " 67%|██████▋   | 79.0M/118M [00:30<00:23, 1.73MB/s]\n",
      " 67%|██████▋   | 79.1M/118M [00:30<00:24, 1.66MB/s]\n",
      " 67%|██████▋   | 79.3M/118M [00:31<00:25, 1.63MB/s]\n",
      " 67%|██████▋   | 79.5M/118M [00:31<00:26, 1.57MB/s]\n",
      " 67%|██████▋   | 79.7M/118M [00:31<00:25, 1.61MB/s]\n",
      " 67%|██████▋   | 79.8M/118M [00:31<00:25, 1.60MB/s]\n",
      " 68%|██████▊   | 80.0M/118M [00:31<00:24, 1.62MB/s]\n",
      " 68%|██████▊   | 80.1M/118M [00:31<00:25, 1.60MB/s]\n",
      " 68%|██████▊   | 80.3M/118M [00:31<00:25, 1.57MB/s]\n",
      " 68%|██████▊   | 80.5M/118M [00:31<00:24, 1.65MB/s]\n",
      " 68%|██████▊   | 80.6M/118M [00:31<00:24, 1.63MB/s]\n",
      " 68%|██████▊   | 80.8M/118M [00:31<00:24, 1.61MB/s]\n",
      " 68%|██████▊   | 81.0M/118M [00:32<00:23, 1.65MB/s]\n",
      " 68%|██████▊   | 81.1M/118M [00:32<00:23, 1.64MB/s]\n",
      " 69%|██████▊   | 81.3M/118M [00:32<00:23, 1.69MB/s]\n",
      " 69%|██████▉   | 81.5M/118M [00:32<00:23, 1.63MB/s]\n",
      " 69%|██████▉   | 81.7M/118M [00:32<00:23, 1.67MB/s]\n",
      " 69%|██████▉   | 81.8M/118M [00:32<00:23, 1.67MB/s]\n",
      " 69%|██████▉   | 82.0M/118M [00:32<00:23, 1.65MB/s]\n",
      " 69%|██████▉   | 82.2M/118M [00:32<00:22, 1.70MB/s]\n",
      " 70%|██████▉   | 82.4M/118M [00:32<00:22, 1.69MB/s]\n",
      " 70%|██████▉   | 82.5M/118M [00:33<00:21, 1.72MB/s]\n",
      " 70%|██████▉   | 82.7M/118M [00:33<00:22, 1.69MB/s]\n",
      " 70%|██████▉   | 82.9M/118M [00:33<00:22, 1.68MB/s]\n",
      " 70%|███████   | 83.1M/118M [00:33<00:21, 1.71MB/s]\n",
      " 70%|███████   | 83.2M/118M [00:33<00:21, 1.71MB/s]\n",
      " 70%|███████   | 83.4M/118M [00:33<00:21, 1.73MB/s]\n",
      " 71%|███████   | 83.6M/118M [00:33<00:21, 1.73MB/s]\n",
      " 71%|███████   | 83.8M/118M [00:33<00:21, 1.71MB/s]\n",
      " 71%|███████   | 84.0M/118M [00:33<00:20, 1.73MB/s]\n",
      " 71%|███████   | 84.1M/118M [00:34<00:21, 1.72MB/s]\n",
      " 71%|███████   | 84.3M/118M [00:34<00:28, 1.28MB/s]\n",
      " 71%|███████▏  | 84.6M/118M [00:34<00:20, 1.73MB/s]\n",
      " 72%|███████▏  | 84.8M/118M [00:34<00:22, 1.57MB/s]\n",
      " 72%|███████▏  | 85.0M/118M [00:34<00:23, 1.49MB/s]\n",
      " 72%|███████▏  | 85.1M/118M [00:34<00:24, 1.43MB/s]\n",
      " 72%|███████▏  | 85.3M/118M [00:34<00:24, 1.43MB/s]\n",
      " 72%|███████▏  | 85.4M/118M [00:35<00:24, 1.39MB/s]\n",
      " 72%|███████▏  | 85.6M/118M [00:35<00:24, 1.40MB/s]\n",
      " 72%|███████▏  | 85.7M/118M [00:35<00:24, 1.40MB/s]\n",
      " 72%|███████▏  | 85.9M/118M [00:35<00:23, 1.43MB/s]\n",
      " 73%|███████▎  | 86.0M/118M [00:35<00:23, 1.42MB/s]\n",
      " 73%|███████▎  | 86.2M/118M [00:35<00:23, 1.44MB/s]\n",
      " 73%|███████▎  | 86.3M/118M [00:35<00:23, 1.43MB/s]\n",
      " 73%|███████▎  | 86.5M/118M [00:35<00:22, 1.48MB/s]\n",
      " 73%|███████▎  | 86.6M/118M [00:35<00:22, 1.50MB/s]\n",
      " 73%|███████▎  | 86.8M/118M [00:35<00:22, 1.51MB/s]\n",
      " 73%|███████▎  | 86.9M/118M [00:36<00:21, 1.54MB/s]\n",
      " 73%|███████▎  | 87.1M/118M [00:36<00:21, 1.53MB/s]\n",
      " 74%|███████▎  | 87.2M/118M [00:36<00:20, 1.56MB/s]\n",
      " 74%|███████▍  | 87.4M/118M [00:36<00:20, 1.57MB/s]\n",
      " 74%|███████▍  | 87.5M/118M [00:36<00:20, 1.58MB/s]\n",
      " 74%|███████▍  | 87.7M/118M [00:36<00:20, 1.61MB/s]\n",
      " 74%|███████▍  | 87.9M/118M [00:36<00:20, 1.60MB/s]\n",
      " 74%|███████▍  | 88.0M/118M [00:36<00:19, 1.63MB/s]\n",
      " 74%|███████▍  | 88.2M/118M [00:36<00:19, 1.65MB/s]\n",
      " 75%|███████▍  | 88.4M/118M [00:37<00:19, 1.64MB/s]\n",
      " 75%|███████▍  | 88.5M/118M [00:37<00:18, 1.66MB/s]\n",
      " 75%|███████▍  | 88.7M/118M [00:37<00:18, 1.65MB/s]\n",
      " 75%|███████▌  | 88.9M/118M [00:37<00:18, 1.67MB/s]\n",
      " 75%|███████▌  | 89.0M/118M [00:37<00:18, 1.67MB/s]\n",
      " 75%|███████▌  | 89.2M/118M [00:37<00:18, 1.67MB/s]\n",
      " 75%|███████▌  | 89.4M/118M [00:37<00:18, 1.69MB/s]\n",
      " 76%|███████▌  | 89.6M/118M [00:37<00:18, 1.68MB/s]\n",
      " 76%|███████▌  | 89.8M/118M [00:37<00:17, 1.72MB/s]\n",
      " 76%|███████▌  | 89.9M/118M [00:37<00:17, 1.71MB/s]\n",
      " 76%|███████▌  | 90.1M/118M [00:38<00:17, 1.71MB/s]\n",
      " 76%|███████▌  | 90.3M/118M [00:38<00:17, 1.72MB/s]\n",
      " 76%|███████▋  | 90.4M/118M [00:38<00:17, 1.71MB/s]\n",
      " 76%|███████▋  | 90.6M/118M [00:38<00:16, 1.73MB/s]\n",
      " 77%|███████▋  | 90.8M/118M [00:38<00:16, 1.72MB/s]\n",
      " 77%|███████▋  | 91.0M/118M [00:38<00:16, 1.73MB/s]\n",
      " 77%|███████▋  | 91.1M/118M [00:38<00:16, 1.74MB/s]\n",
      " 77%|███████▋  | 91.3M/118M [00:38<00:16, 1.70MB/s]\n",
      " 77%|███████▋  | 91.5M/118M [00:38<00:16, 1.73MB/s]\n",
      " 77%|███████▋  | 91.7M/118M [00:39<00:16, 1.71MB/s]\n",
      " 78%|███████▊  | 91.8M/118M [00:39<00:16, 1.73MB/s]\n",
      " 78%|███████▊  | 92.0M/118M [00:39<00:15, 1.74MB/s]\n",
      " 78%|███████▊  | 92.2M/118M [00:39<00:19, 1.40MB/s]\n",
      " 78%|███████▊  | 92.4M/118M [00:39<00:16, 1.68MB/s]\n",
      " 78%|███████▊  | 92.6M/118M [00:39<00:17, 1.55MB/s]\n",
      " 78%|███████▊  | 92.8M/118M [00:39<00:18, 1.45MB/s]\n",
      " 78%|███████▊  | 92.9M/118M [00:39<00:18, 1.43MB/s]\n",
      " 79%|███████▊  | 93.1M/118M [00:40<00:19, 1.37MB/s]\n",
      " 79%|███████▊  | 93.2M/118M [00:40<00:18, 1.40MB/s]\n",
      " 79%|███████▉  | 93.3M/118M [00:40<00:19, 1.36MB/s]\n",
      " 79%|███████▉  | 93.5M/118M [00:40<00:18, 1.39MB/s]\n",
      " 79%|███████▉  | 93.6M/118M [00:40<00:19, 1.32MB/s]\n",
      " 79%|███████▉  | 93.8M/118M [00:40<00:18, 1.43MB/s]\n",
      " 79%|███████▉  | 94.0M/118M [00:40<00:20, 1.25MB/s]\n",
      " 79%|███████▉  | 94.1M/118M [00:40<00:20, 1.27MB/s]\n",
      " 80%|███████▉  | 94.2M/118M [00:40<00:18, 1.40MB/s]\n",
      " 80%|███████▉  | 94.4M/118M [00:41<00:18, 1.39MB/s]\n",
      " 80%|███████▉  | 94.6M/118M [00:41<00:17, 1.44MB/s]\n",
      " 80%|███████▉  | 94.8M/118M [00:41<00:16, 1.52MB/s]\n",
      " 80%|████████  | 94.9M/118M [00:41<00:16, 1.51MB/s]\n",
      " 80%|████████  | 95.1M/118M [00:41<00:15, 1.59MB/s]\n",
      " 80%|████████  | 95.2M/118M [00:41<00:15, 1.55MB/s]\n",
      " 81%|████████  | 95.4M/118M [00:41<00:15, 1.55MB/s]\n",
      " 81%|████████  | 95.6M/118M [00:41<00:14, 1.60MB/s]\n",
      " 81%|████████  | 95.7M/118M [00:41<00:15, 1.58MB/s]\n",
      " 81%|████████  | 95.9M/118M [00:42<00:14, 1.63MB/s]\n",
      " 81%|████████  | 96.1M/118M [00:42<00:14, 1.64MB/s]\n",
      " 81%|████████  | 96.2M/118M [00:42<00:14, 1.66MB/s]\n",
      " 81%|████████▏ | 96.4M/118M [00:42<00:14, 1.65MB/s]\n",
      " 81%|████████▏ | 96.6M/118M [00:42<00:13, 1.67MB/s]\n",
      " 82%|████████▏ | 96.7M/118M [00:42<00:13, 1.68MB/s]\n",
      " 82%|████████▏ | 96.9M/118M [00:42<00:13, 1.69MB/s]\n",
      " 82%|████████▏ | 97.1M/118M [00:42<00:13, 1.66MB/s]\n",
      " 82%|████████▏ | 97.2M/118M [00:42<00:13, 1.71MB/s]\n",
      " 82%|████████▏ | 97.4M/118M [00:42<00:13, 1.69MB/s]\n",
      " 82%|████████▏ | 97.6M/118M [00:43<00:12, 1.70MB/s]\n",
      " 83%|████████▎ | 97.8M/118M [00:43<00:12, 1.69MB/s]\n",
      " 83%|████████▎ | 97.9M/118M [00:43<00:12, 1.70MB/s]\n",
      " 83%|████████▎ | 98.1M/118M [00:43<00:12, 1.71MB/s]\n",
      " 83%|████████▎ | 98.3M/118M [00:43<00:12, 1.71MB/s]\n",
      " 83%|████████▎ | 98.5M/118M [00:43<00:12, 1.71MB/s]\n",
      " 83%|████████▎ | 98.6M/118M [00:43<00:11, 1.73MB/s]\n",
      " 83%|████████▎ | 98.8M/118M [00:43<00:11, 1.72MB/s]\n",
      " 84%|████████▎ | 99.0M/118M [00:43<00:11, 1.71MB/s]\n",
      " 84%|████████▎ | 99.2M/118M [00:44<00:11, 1.72MB/s]\n",
      " 84%|████████▍ | 99.3M/118M [00:44<00:11, 1.70MB/s]\n",
      " 84%|████████▍ | 99.5M/118M [00:44<00:11, 1.75MB/s]\n",
      " 84%|████████▍ | 99.7M/118M [00:44<00:11, 1.72MB/s]\n",
      " 84%|████████▍ | 99.9M/118M [00:44<00:11, 1.74MB/s]\n",
      " 84%|████████▍ | 100M/118M [00:44<00:11, 1.73MB/s] \n",
      " 85%|████████▍ | 100M/118M [00:44<00:11, 1.72MB/s]\n",
      " 85%|████████▍ | 100M/118M [00:44<00:10, 1.74MB/s]\n",
      " 85%|████████▍ | 101M/118M [00:44<00:10, 1.72MB/s]\n",
      " 85%|████████▌ | 101M/118M [00:45<00:10, 1.71MB/s]\n",
      " 85%|████████▌ | 101M/118M [00:45<00:10, 1.72MB/s]\n",
      " 85%|████████▌ | 101M/118M [00:45<00:10, 1.71MB/s]\n",
      " 85%|████████▌ | 101M/118M [00:45<00:10, 1.75MB/s]\n",
      " 86%|████████▌ | 101M/118M [00:45<00:10, 1.72MB/s]\n",
      " 86%|████████▌ | 102M/118M [00:45<00:10, 1.71MB/s]\n",
      " 86%|████████▌ | 102M/118M [00:45<00:10, 1.73MB/s]\n",
      " 86%|████████▌ | 102M/118M [00:45<00:10, 1.72MB/s]\n",
      " 86%|████████▌ | 102M/118M [00:45<00:09, 1.73MB/s]\n",
      " 86%|████████▋ | 102M/118M [00:45<00:09, 1.73MB/s]\n",
      " 86%|████████▋ | 102M/118M [00:46<00:09, 1.71MB/s]\n",
      " 87%|████████▋ | 103M/118M [00:46<00:09, 1.74MB/s]\n",
      " 87%|████████▋ | 103M/118M [00:46<00:09, 1.71MB/s]\n",
      " 87%|████████▋ | 103M/118M [00:46<00:09, 1.75MB/s]\n",
      " 87%|████████▋ | 103M/118M [00:46<00:09, 1.75MB/s]\n",
      " 87%|████████▋ | 103M/118M [00:46<00:09, 1.73MB/s]\n",
      " 87%|████████▋ | 104M/118M [00:46<00:08, 1.77MB/s]\n",
      " 88%|████████▊ | 104M/118M [00:46<00:08, 1.73MB/s]\n",
      " 88%|████████▊ | 104M/118M [00:46<00:08, 1.73MB/s]\n",
      " 88%|████████▊ | 104M/118M [00:47<00:08, 1.78MB/s]\n",
      " 88%|████████▊ | 104M/118M [00:47<00:08, 1.75MB/s]\n",
      " 88%|████████▊ | 104M/118M [00:47<00:08, 1.80MB/s]\n",
      " 88%|████████▊ | 105M/118M [00:47<00:08, 1.76MB/s]\n",
      " 88%|████████▊ | 105M/118M [00:47<00:08, 1.74MB/s]\n",
      " 89%|████████▊ | 105M/118M [00:47<00:07, 1.79MB/s]\n",
      " 89%|████████▉ | 105M/118M [00:47<00:07, 1.76MB/s]\n",
      " 89%|████████▉ | 105M/118M [00:47<00:07, 1.82MB/s]\n",
      " 89%|████████▉ | 106M/118M [00:47<00:07, 1.83MB/s]\n",
      " 89%|████████▉ | 106M/118M [00:48<00:07, 1.77MB/s]\n",
      " 89%|████████▉ | 106M/118M [00:48<00:07, 1.84MB/s]\n",
      " 90%|████████▉ | 106M/118M [00:48<00:07, 1.82MB/s]\n",
      " 90%|████████▉ | 106M/118M [00:48<00:07, 1.75MB/s]\n",
      " 90%|████████▉ | 107M/118M [00:48<00:06, 1.88MB/s]\n",
      " 90%|█████████ | 107M/118M [00:48<00:06, 1.86MB/s]\n",
      " 90%|█████████ | 107M/118M [00:48<00:06, 1.91MB/s]\n",
      " 90%|█████████ | 107M/118M [00:48<00:06, 1.86MB/s]\n",
      " 91%|█████████ | 107M/118M [00:48<00:06, 1.91MB/s]\n",
      " 91%|█████████ | 107M/118M [00:48<00:06, 1.92MB/s]\n",
      " 91%|█████████ | 108M/118M [00:49<00:05, 1.90MB/s]\n",
      " 91%|█████████ | 108M/118M [00:49<00:05, 1.97MB/s]\n",
      " 91%|█████████ | 108M/118M [00:49<00:05, 1.95MB/s]\n",
      " 91%|█████████▏| 108M/118M [00:49<00:05, 2.01MB/s]\n",
      " 92%|█████████▏| 108M/118M [00:49<00:05, 1.99MB/s]\n",
      " 92%|█████████▏| 109M/118M [00:49<00:05, 2.00MB/s]\n",
      " 92%|█████████▏| 109M/118M [00:49<00:04, 2.08MB/s]\n",
      " 92%|█████████▏| 109M/118M [00:49<00:04, 2.04MB/s]\n",
      " 92%|█████████▏| 109M/118M [00:49<00:04, 2.13MB/s]\n",
      " 92%|█████████▏| 110M/118M [00:50<00:04, 2.12MB/s]\n",
      " 93%|█████████▎| 110M/118M [00:50<00:04, 2.11MB/s]\n",
      " 93%|█████████▎| 110M/118M [00:50<00:04, 2.19MB/s]\n",
      " 93%|█████████▎| 110M/118M [00:50<00:03, 2.18MB/s]\n",
      " 93%|█████████▎| 110M/118M [00:50<00:03, 2.28MB/s]\n",
      " 93%|█████████▎| 111M/118M [00:50<00:03, 2.23MB/s]\n",
      " 94%|█████████▎| 111M/118M [00:50<00:03, 2.25MB/s]\n",
      " 94%|█████████▍| 111M/118M [00:50<00:03, 2.34MB/s]\n",
      " 94%|█████████▍| 111M/118M [00:50<00:03, 2.34MB/s]\n",
      " 94%|█████████▍| 112M/118M [00:50<00:02, 2.41MB/s]\n",
      " 94%|█████████▍| 112M/118M [00:51<00:02, 2.39MB/s]\n",
      " 95%|█████████▍| 112M/118M [00:51<00:02, 2.45MB/s]\n",
      " 95%|█████████▍| 112M/118M [00:51<00:02, 2.50MB/s]\n",
      " 95%|█████████▌| 113M/118M [00:51<00:02, 2.53MB/s]\n",
      " 95%|█████████▌| 113M/118M [00:51<00:02, 2.61MB/s]\n",
      " 96%|█████████▌| 113M/118M [00:51<00:02, 2.60MB/s]\n",
      " 96%|█████████▌| 113M/118M [00:51<00:02, 1.99MB/s]\n",
      " 96%|█████████▌| 114M/118M [00:51<00:01, 2.66MB/s]\n",
      " 96%|█████████▋| 114M/118M [00:52<00:01, 2.48MB/s]\n",
      " 97%|█████████▋| 114M/118M [00:52<00:01, 2.31MB/s]\n",
      " 97%|█████████▋| 115M/118M [00:52<00:01, 2.23MB/s]\n",
      " 97%|█████████▋| 115M/118M [00:52<00:01, 2.19MB/s]\n",
      " 97%|█████████▋| 115M/118M [00:52<00:01, 2.20MB/s]\n",
      " 97%|█████████▋| 115M/118M [00:52<00:01, 2.18MB/s]\n",
      " 98%|█████████▊| 116M/118M [00:52<00:01, 2.24MB/s]\n",
      " 98%|█████████▊| 116M/118M [00:52<00:01, 2.14MB/s]\n",
      " 98%|█████████▊| 116M/118M [00:52<00:01, 2.23MB/s]\n",
      " 98%|█████████▊| 116M/118M [00:53<00:01, 2.24MB/s]\n",
      " 98%|█████████▊| 116M/118M [00:53<00:00, 2.24MB/s]\n",
      " 99%|█████████▊| 117M/118M [00:53<00:00, 2.34MB/s]\n",
      " 99%|█████████▊| 117M/118M [00:53<00:00, 2.33MB/s]\n",
      " 99%|█████████▉| 117M/118M [00:53<00:00, 2.41MB/s]\n",
      " 99%|█████████▉| 117M/118M [00:53<00:00, 2.38MB/s]\n",
      " 99%|█████████▉| 118M/118M [00:53<00:00, 2.38MB/s]\n",
      "100%|█████████▉| 118M/118M [00:53<00:00, 2.48MB/s]\n",
      "100%|█████████▉| 118M/118M [00:53<00:00, 2.46MB/s]\n",
      "100%|██████████| 118M/118M [00:53<00:00, 2.58MB/s]\n",
      "100%|██████████| 118M/118M [00:53<00:00, 2.30MB/s]\n",
      "Fusing layers... \n",
      "Model Summary: 261 layers, 61922845 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "# clone repo\n",
    "!git clone https://github.com/ultralytics/yolov3\n",
    "\n",
    "%cd yolov3/\n",
    "# install dependencies\n",
    "!pip install -qr requirements.txt\n",
    "\n",
    "#sample\n",
    "!python detect.py --weights yolov3.pt --img 640 --conf 0.25 --source data/images/\n",
    "\n",
    "%cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5/\n",
    "# Run YOLOv5x on COCO val2017\n",
    "if torch.cuda.is_available():\n",
    "    print('Eval with gpu')\n",
    "    !python val.py --weights yolov5s.pt --data data/coco.yaml --img 640 --iou 0.65 --half\n",
    "else:\n",
    "    print('Eval with cpu')\n",
    "    !python val.py --weights yolov5s.pt --data data/coco.yaml --img 640 --iou 0.65 --device='cpu'\n",
    "%cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to move the dataset folder as test.py doesn't work with coco.yaml from yolov5 wich as a different folder structure\n",
    "# as well test.py doesn't work if it's not executed from another folder cause it check the presence of requirements.txt...\n",
    "!mv ./datasets/coco ./\n",
    "%cd yolov3/\n",
    "!python test.py --weights yolov3.pt --data data/coco.yaml --img 640 --iou 0.65\n",
    "\n",
    "\n",
    "%cd /kaggle/working/\n",
    "# # put back ds in datasets/ folder\n",
    "!mv ./coco ./datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD YOLO FROM PYTORCH HUB\n",
    "This example loads a pretrained YOLOv5s model and passes an image for inference.\n",
    "YOLOv5 accepts URL, Filename, PIL, OpenCV, Numpy and PyTorch inputs, and returns detections in torch, pandas, and JSON output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# from IPython.display import Image, clear_output  # to display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Admin/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2021-10-6 torch 1.9.1+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s6.pt to C:\\Users\\Admin\\.cache\\torch\\hub\\ultralytics_yolov5_master\\yolov5s6.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24.6M/24.6M [00:04<00:00, 5.19MB/s]\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 291 layers, 12653596 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/modelYv5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23460/3475880398.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodelYv5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ultralytics/yolov5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yolov5s6'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelYv5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'models/modelYv5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\env_p7\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env_p7\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env_p7\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/modelYv5'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model\n",
    "modelYv5 = torch.hub.load('ultralytics/yolov5', 'yolov5s6', pretrained=True)\n",
    "torch.save(modelYv5, 'models/modelYv5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping utils as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov3/archive/master.zip\" to C:\\Users\\Admin/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.google_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23460/1919191825.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/modelYv3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodelYv3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ultralytics/yolov3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yolov3_tiny'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelYv3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'models/modelYv3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env_p7\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mrepo_or_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_cache_or_reload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env_p7\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov3_master\\hubconf.py\u001b[0m in \u001b[0;36myolov3_tiny\u001b[1;34m(pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0myolov3_tiny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# YOLOv3-tiny model https://github.com/ultralytics/yolov3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolov3-tiny'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov3_master\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_requirements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoogle_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mattempt_download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mselect_device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils.google_utils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not(os.path.exists('models/modelYv3')):\n",
    "    modelYv3 = torch.hub.load('ultralytics/yolov3', 'yolov3_tiny', pretrained=True, force_reload=True)\n",
    "    torch.save(modelYv3, 'models/modelYv3')\n",
    "else:\n",
    "    modelYv3 = torch.load('models/modelYv3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed Example\n",
    "This example shows batched inference with PIL and OpenCV image sources. results can be printed to console, saved to runs/hub, showed to screen on supported environments, and returned as tensors or pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165k/165k [00:00<00:00, 433kB/s]\n",
      "100%|██████████| 476k/476k [00:00<00:00, 651kB/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23460/364366553.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelYv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# includes NMS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "# Dl images\n",
    "for f in ['zidane.jpg', 'bus.jpg']:\n",
    "    torch.hub.download_url_to_file('https://ultralytics.com/images/' + f, f)  # download 2 images\n",
    "\n",
    "img1 = Image.open('zidane.jpg')  # PIL image\n",
    "img2 = cv2.imread('bus.jpg')[..., ::-1]  # OpenCV image (BGR to RGB)\n",
    "imgs = [img1, img2]  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = modelYv3(imgs, size=640)  # includes NMS\n",
    "\n",
    "# Results\n",
    "results.print()  \n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "for i in range(len(results.pandas().xyxy)):\n",
    "    display(results.pandas().xyxy[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference Settings\n",
    "Inference settings such as confidence threshold, NMS IoU threshold, and classes filter are model attributes, and can be modified by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conf = 0.25  # confidence threshold (0-1)\n",
    "model.iou = 0.45  # NMS IoU threshold (0-1)\n",
    "model.classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n",
    "\n",
    "results = model(imgs, size=320)  # custom inference size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a pretrained YOLOv5s model with 10 output classes rather than the default 80:\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run inference on your desktop screen:\n",
    "import torch\n",
    "from PIL import ImageGrab\n",
    "\n",
    "# Model\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Image\n",
    "img = ImageGrab.grab()  # take a screenshot\n",
    "\n",
    "# Inference\n",
    "results = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1839.793701</td>\n",
       "      <td>1099.630127</td>\n",
       "      <td>2030.106567</td>\n",
       "      <td>1535.244507</td>\n",
       "      <td>0.746785</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>899.325439</td>\n",
       "      <td>1058.016724</td>\n",
       "      <td>1001.593323</td>\n",
       "      <td>1302.591064</td>\n",
       "      <td>0.705910</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2093.371582</td>\n",
       "      <td>1218.878052</td>\n",
       "      <td>2412.072754</td>\n",
       "      <td>1419.645264</td>\n",
       "      <td>0.700631</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596.646118</td>\n",
       "      <td>1075.654541</td>\n",
       "      <td>1717.967773</td>\n",
       "      <td>1432.974976</td>\n",
       "      <td>0.696707</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1492.568481</td>\n",
       "      <td>1098.156860</td>\n",
       "      <td>1636.106323</td>\n",
       "      <td>1473.797363</td>\n",
       "      <td>0.692770</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1992.815918</td>\n",
       "      <td>1071.272095</td>\n",
       "      <td>2102.857910</td>\n",
       "      <td>1441.544922</td>\n",
       "      <td>0.659345</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2208.543701</td>\n",
       "      <td>1053.941406</td>\n",
       "      <td>2347.497070</td>\n",
       "      <td>1368.726929</td>\n",
       "      <td>0.622297</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1300.317993</td>\n",
       "      <td>1074.484375</td>\n",
       "      <td>1364.203613</td>\n",
       "      <td>1254.715576</td>\n",
       "      <td>0.582750</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2630.947510</td>\n",
       "      <td>1096.999878</td>\n",
       "      <td>2748.509766</td>\n",
       "      <td>1204.348511</td>\n",
       "      <td>0.557612</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32.052223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>714.420471</td>\n",
       "      <td>1694.689453</td>\n",
       "      <td>0.489314</td>\n",
       "      <td>63</td>\n",
       "      <td>laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.320793</td>\n",
       "      <td>13.616821</td>\n",
       "      <td>703.070496</td>\n",
       "      <td>1699.288086</td>\n",
       "      <td>0.480147</td>\n",
       "      <td>62</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3019.683838</td>\n",
       "      <td>1140.436646</td>\n",
       "      <td>3090.087891</td>\n",
       "      <td>1298.441162</td>\n",
       "      <td>0.470145</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>715.021179</td>\n",
       "      <td>1441.159424</td>\n",
       "      <td>1009.412659</td>\n",
       "      <td>1890.660278</td>\n",
       "      <td>0.425281</td>\n",
       "      <td>3</td>\n",
       "      <td>motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1064.004639</td>\n",
       "      <td>1139.112183</td>\n",
       "      <td>1200.923340</td>\n",
       "      <td>1287.660889</td>\n",
       "      <td>0.384974</td>\n",
       "      <td>3</td>\n",
       "      <td>motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1846.830322</td>\n",
       "      <td>1233.650024</td>\n",
       "      <td>1917.791382</td>\n",
       "      <td>1340.449097</td>\n",
       "      <td>0.371072</td>\n",
       "      <td>26</td>\n",
       "      <td>handbag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1843.394287</td>\n",
       "      <td>1178.162476</td>\n",
       "      <td>1956.936890</td>\n",
       "      <td>1421.966431</td>\n",
       "      <td>0.315354</td>\n",
       "      <td>26</td>\n",
       "      <td>handbag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2972.189941</td>\n",
       "      <td>1134.690796</td>\n",
       "      <td>3013.511230</td>\n",
       "      <td>1199.081177</td>\n",
       "      <td>0.299520</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2432.158447</td>\n",
       "      <td>1134.513428</td>\n",
       "      <td>2496.323975</td>\n",
       "      <td>1206.331177</td>\n",
       "      <td>0.274357</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1486.217651</td>\n",
       "      <td>1224.761353</td>\n",
       "      <td>1546.915649</td>\n",
       "      <td>1332.493652</td>\n",
       "      <td>0.273415</td>\n",
       "      <td>26</td>\n",
       "      <td>handbag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3084.796387</td>\n",
       "      <td>1138.069702</td>\n",
       "      <td>3123.172363</td>\n",
       "      <td>1256.521729</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           xmin         ymin         xmax         ymax  confidence  class  \\\n",
       "0   1839.793701  1099.630127  2030.106567  1535.244507    0.746785      0   \n",
       "1    899.325439  1058.016724  1001.593323  1302.591064    0.705910      0   \n",
       "2   2093.371582  1218.878052  2412.072754  1419.645264    0.700631      1   \n",
       "3   1596.646118  1075.654541  1717.967773  1432.974976    0.696707      0   \n",
       "4   1492.568481  1098.156860  1636.106323  1473.797363    0.692770      0   \n",
       "5   1992.815918  1071.272095  2102.857910  1441.544922    0.659345      0   \n",
       "6   2208.543701  1053.941406  2347.497070  1368.726929    0.622297      0   \n",
       "7   1300.317993  1074.484375  1364.203613  1254.715576    0.582750      0   \n",
       "8   2630.947510  1096.999878  2748.509766  1204.348511    0.557612      2   \n",
       "9     32.052223     0.000000   714.420471  1694.689453    0.489314     63   \n",
       "10    62.320793    13.616821   703.070496  1699.288086    0.480147     62   \n",
       "11  3019.683838  1140.436646  3090.087891  1298.441162    0.470145      0   \n",
       "12   715.021179  1441.159424  1009.412659  1890.660278    0.425281      3   \n",
       "13  1064.004639  1139.112183  1200.923340  1287.660889    0.384974      3   \n",
       "14  1846.830322  1233.650024  1917.791382  1340.449097    0.371072     26   \n",
       "15  1843.394287  1178.162476  1956.936890  1421.966431    0.315354     26   \n",
       "16  2972.189941  1134.690796  3013.511230  1199.081177    0.299520      0   \n",
       "17  2432.158447  1134.513428  2496.323975  1206.331177    0.274357      0   \n",
       "18  1486.217651  1224.761353  1546.915649  1332.493652    0.273415     26   \n",
       "19  3084.796387  1138.069702  3123.172363  1256.521729    0.251701      0   \n",
       "\n",
       "          name  \n",
       "0       person  \n",
       "1       person  \n",
       "2      bicycle  \n",
       "3       person  \n",
       "4       person  \n",
       "5       person  \n",
       "6       person  \n",
       "7       person  \n",
       "8          car  \n",
       "9       laptop  \n",
       "10          tv  \n",
       "11      person  \n",
       "12  motorcycle  \n",
       "13  motorcycle  \n",
       "14     handbag  \n",
       "15     handbag  \n",
       "16      person  \n",
       "17      person  \n",
       "18     handbag  \n",
       "19      person  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and predict on another ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import Image  # for displaying images\n",
    "import os \n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we are going to use an object detection dataset of road signs from MakeML.\n",
    "It is a dataset that contains road signs belonging to 4 classes:\n",
    "\n",
    "Traffic Light\n",
    "Stop\n",
    "Speed Limit\n",
    "Crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Road_Sign_Dataset\n",
    "!cd Road_Sign_Dataset\n",
    "!wget -O RoadSignDetectionDataset.zip https://arcraftimages.s3-accelerate.amazonaws.com/Datasets/RoadSigns/RoadSignsPascalVOC.zip?region=us-east-2\n",
    "\n",
    "\n",
    "!unzip RoadSignDetectionDataset.zip\n",
    "\n",
    "!rm -r __MACOSX RoadSignDetectionDataset.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Annotations into the YOLO v5 Format\n",
    "In this part, we convert annotations into the format expected by YOLO v5. There are a variety of formats when it comes to annotations for object detection datasets.\n",
    "\n",
    "Annotations for the dataset we downloaded follow the PASCAL VOC XML format, which is a very popular format. Since this a popular format, you can find online conversion tools. Nevertheless, we are going to write the code for it to give you some idea of how to convert lesser popular formats as well (for which you may not find popular tools).\n",
    "\n",
    "The PASCAL VOC format stores its annotation in XML files where various attributes are described by tags. Let us look at one such annotation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "# Assuming you're in the data folder\n",
    "!cat annotations/road4.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# YOLO v5 expects annotations for each image in form of a .txt file where each line of the text file describes a bounding box. Consider the following image.\n",
    "# Function to get the data from XML Annotation\n",
    "def extract_info_from_xml(xml_file):\n",
    "    root = ET.parse(xml_file).getroot()\n",
    "    \n",
    "    # Initialise the info dict \n",
    "    info_dict = {}\n",
    "    info_dict['bboxes'] = []\n",
    "\n",
    "    # Parse the XML Tree\n",
    "    for elem in root:\n",
    "        # Get the file name \n",
    "        if elem.tag == \"filename\":\n",
    "            info_dict['filename'] = elem.text\n",
    "            \n",
    "        # Get the image size\n",
    "        elif elem.tag == \"size\":\n",
    "            image_size = []\n",
    "            for subelem in elem:\n",
    "                image_size.append(int(subelem.text))\n",
    "            \n",
    "            info_dict['image_size'] = tuple(image_size)\n",
    "        \n",
    "        # Get details of the bounding box \n",
    "        elif elem.tag == \"object\":\n",
    "            bbox = {}\n",
    "            for subelem in elem:\n",
    "                if subelem.tag == \"name\":\n",
    "                    bbox[\"class\"] = subelem.text\n",
    "                    \n",
    "                elif subelem.tag == \"bndbox\":\n",
    "                    for subsubelem in subelem:\n",
    "                        bbox[subsubelem.tag] = int(subsubelem.text)            \n",
    "            info_dict['bboxes'].append(bbox)\n",
    "    \n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that maps class names to IDs\n",
    "class_name_to_id_mapping = {\"trafficlight\": 0,\n",
    "                           \"stop\": 1,\n",
    "                           \"speedlimit\": 2,\n",
    "                           \"crosswalk\": 3}\n",
    "\n",
    "# Convert the info dict to the required yolo format and write it to disk\n",
    "def convert_to_yolov5(info_dict):\n",
    "    print_buffer = []\n",
    "    \n",
    "    # For each bounding box\n",
    "    for b in info_dict[\"bboxes\"]:\n",
    "        try:\n",
    "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
    "        except KeyError:\n",
    "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
    "        \n",
    "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
    "        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n",
    "        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
    "        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
    "        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
    "        \n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w, image_h, image_c = info_dict[\"image_size\"]  \n",
    "        b_center_x /= image_w \n",
    "        b_center_y /= image_h \n",
    "        b_width    /= image_w \n",
    "        b_height   /= image_h \n",
    "        \n",
    "        #Write the bbox details to the file \n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
    "        \n",
    "    # Name of the file which we have to save \n",
    "    save_file_name = os.path.join(\"annotations\", info_dict[\"filename\"].replace(\"png\", \"txt\"))\n",
    "    \n",
    "    # Save the annotation to disk\n",
    "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the annotations\n",
    "annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"xml\"]\n",
    "annotations.sort()\n",
    "\n",
    "# Convert and save the annotations\n",
    "for ann in tqdm(annotations):\n",
    "    info_dict = extract_info_from_xml(ann)\n",
    "    convert_to_yolov5(info_dict)\n",
    "annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "random.seed(0)\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "def plot_bounding_box(image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(image)\n",
    "\n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "    \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)))\n",
    "        \n",
    "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
    "    \n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()\n",
    "\n",
    "# Get any random annotation file \n",
    "annotation_file = random.choice(annotations)\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "\n",
    "#Get the corresponding image file\n",
    "image_file = annotation_file.replace(\"annotations\", \"images\").replace(\"txt\", \"png\")\n",
    "assert os.path.exists(image_file)\n",
    "\n",
    "#Load the image\n",
    "image = Image.open(image_file)\n",
    "\n",
    "#Plot the Bounding Box\n",
    "plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and annotations\n",
    "images = [os.path.join('images', x) for x in os.listdir('images')]\n",
    "annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Split the dataset into train-valid-test splits \n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images/train images/val images/test annotations/train annotations/val annotations/test\n",
    "\n",
    "\n",
    "#Utility function to move images \n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_folder(train_images, 'images/train')\n",
    "move_files_to_folder(val_images, 'images/val/')\n",
    "move_files_to_folder(test_images, 'images/test/')\n",
    "move_files_to_folder(train_annotations, 'annotations/train/')\n",
    "move_files_to_folder(val_annotations, 'annotations/val/')\n",
    "move_files_to_folder(test_annotations, 'annotations/test/')\n",
    "\n",
    "!mv annotations labels\n",
    "!cd ../yolov5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Details for the dataset you want to train your model on are defined by the data config YAML file. The following parameters have to be defined in a data config file:\n",
    "\n",
    "train, test, and val: Locations of train, test, and validation images.\n",
    "nc: Number of classes in the dataset.\n",
    "names: Names of the classes in the dataset. The index of the classes in this list would be used as an identifier for the class names in the code.\n",
    "\n",
    "Create a new file called road_sign_data.yaml and place it in the yolov5/data folder. Then populate it with the following.\n",
    "\n",
    "train: ../Road_Sign_Dataset/images/train/ \n",
    "val:  ../Road_Sign_Dataset/images/val/\n",
    "test: ../Road_Sign_Dataset/images/test/\n",
    "\n",
    "# number of classes\n",
    "nc: 4\n",
    "\n",
    "# class names\n",
    "names: [\"trafficlight\",\"stop\", \"speedlimit\",\"crosswalk\"] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7863/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7863/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2c6a5f0d3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18724/1551809678.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'zidane.jpg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bus.jpg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m gr.Interface(yolo, inputs=[in1, in2], outputs=outputs, title=title, description=description, article=article, examples=examples, analytics_enabled=False).launch(\n\u001b[0m\u001b[0;32m     36\u001b[0m     debug=True)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env_p7\\lib\\site-packages\\gradio\\interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[1;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ps1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mprevent_thread_lock\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# !pip install gradio\n",
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Images\n",
    "# torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg', 'zidane.jpg')\n",
    "# torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/raw/master/data/images/bus.jpg', 'bus.jpg')\n",
    "\n",
    "# Model\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # force_reload=True to update\n",
    "\n",
    "\n",
    "def yolo(model_idx, im, size=640):\n",
    "    g = (size / max(im.size))  # gain\n",
    "    im = im.resize((int(x * g) for x in im.size), Image.ANTIALIAS)  # resize\n",
    "    if model_idx == 0:\n",
    "        results = modelYv3(im)  # inference\n",
    "    elif model_idx == 1:\n",
    "        results = modelYv5(im)  # inference\n",
    "    else:\n",
    "        break\n",
    "    results.render()  # updates results.imgs with boxes and labels\n",
    "    return Image.fromarray(results.imgs[0])\n",
    "\n",
    "in1 = gr.inputs.Radio(['YOLOv3', 'YOLOv5'], label=\"Model\", type='index')\n",
    "in2 = gr.inputs.Image(type='pil', label=\"Original Image\")\n",
    "outputs = gr.outputs.Image(type=\"pil\", label=\"Output Image\")\n",
    "\n",
    "title = \"YOLOv5\"\n",
    "description = \"YOLOv5 Gradio demo for object detection. Upload an image or click an example image to use.\"\n",
    "article = \"<p style='text-align: center'>YOLOv5 is a family of compound-scaled object detection models trained on the COCO dataset, and includes \" \\\n",
    "          \"simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, \" \\\n",
    "          \"and export to ONNX, CoreML and TFLite. <a href='https://github.com/ultralytics/yolov5'>Source code</a> |\" \\\n",
    "          \"<a href='https://apps.apple.com/app/id1452689527'>iOS App</a> | <a href='https://pytorch.org/hub/ultralytics_yolov5'>PyTorch Hub</a></p>\"\n",
    "\n",
    "examples = [['zidane.jpg'], ['bus.jpg']]\n",
    "gr.Interface(yolo, inputs=[in1, in2], outputs=outputs, title=title, description=description, article=article, examples=examples, analytics_enabled=False).launch(\n",
    "    debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steamlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run P7_02_code.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be2e9e7436fe9a4dd83f8bf9cf41177d596f0a454d366cdff8746e377458e3df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env_p7': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
